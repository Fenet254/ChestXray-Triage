# ChestXrayâ€‘Triage â€” Deep Learning Capstone

## ğŸš€ Overview

This project is a **fullâ€‘stack deep learning system** for multiâ€‘label chest Xâ€‘ray triage. It predicts multiple thoracic diseases (e.g., Pneumonia, Tuberculosis, Pleural Effusion) from chest radiographs, ranks urgency, and provides visual explanations with **Gradâ€‘CAM heatmaps**. The project follows a **1â€‘month endâ€‘toâ€‘end workflow**: idea â†’ dataset â†’ model â†’ improvements â†’ evaluation â†’ deployment â†’ documentation â†’ presentation.

âš ï¸ **Disclaimer**: This system is for **educational and research purposes only**. It is **not a medical diagnostic tool** and must not be used for clinical decisionâ€‘making.

---

## ğŸ“Œ Goals

* Build a reproducible **computer vision pipeline** for chest Xâ€‘ray triage.
* Implement a **baseline model** and at least **three meaningful improvements**.
* Evaluate with AUROC, F1, PRâ€‘AUC, confusion matrices, calibration, and error analysis.
* Deploy a working demo (web app with Streamlit/FastAPI).
* Deliver full documentation: Data Card, research paper, PPT deck, and recorded videos.

---


## ğŸ“‚ Repository Structure

```
chestxray-triage/
  README.md
  RUN.md
  LICENSE
  data/
    raw/            # raw datasets (gitignored)
    processed/      # processed splits & metadata
    metadata.csv
    label_map.json
  configs/          # experiment configs (baseline, improvements)
  src/
    data/           # dataset & transform loaders
    models/         # model definitions
    app/            # deployment (Streamlit/FastAPI)
    train.py        # training script
    eval.py         # evaluation script
    gradcam.py      # Grad-CAM explainability
    export.py       # ONNX/TFLite export
    infer.py        # CLI inference
  scripts/          # preprocessing & setup scripts
  notebooks/        # EDA, error analysis, ablations
  tests/            # unit tests for reproducibility
  environment.yml   # conda environment file
  requirements.txt  # pip dependencies
  Makefile          # one-line workflows
```

---

## âš™ï¸ Quickstart

### 1. Setup environment

```bash
conda env create -f environment.yml
conda activate cxr
```

### 2. Prepare data

```bash
python scripts/preprocess.py --config configs/baseline.yaml
```

### 3. Train a baseline

```bash
python -m src.train --config configs/baseline.yaml
```

### 4. Evaluate

```bash
python -m src.eval --ckpt runs/baseline/best.ckpt --split test
```

### 5. Run Gradâ€‘CAM

```bash
python -m src.gradcam --ckpt runs/final/best.ckpt --images demo/
```

### 6. Launch demo app

```bash
streamlit run src/app/streamlit_app.py
```

---

## ğŸ§ª Model Improvements (Planned)

1. **Stronger backbone & higher resolution** (EfficientNetV2 / ConvNeXt).
2. **Loss functions for class imbalance** (Focal loss, classâ€‘weighted BCE).
3. **Calibration & TTA** (temperature scaling, testâ€‘time augmentations).

Optional: MixUp/CutMix, selfâ€‘supervised pretraining, lightweight ensembling.

---

## ğŸ“Š Evaluation Metrics

* **Macro AUROC** (primary)
* **Macro & perâ€‘class F1**
* **Precisionâ€‘Recall AUC** for critical classes (TB, Pneumonia, Effusion)
* **Confusion matrices** & **error boards**
* **Calibration metrics** (ECE, reliability diagrams)
* **Latency measurements** (GPU vs CPU)

---

## ğŸ–¥ï¸ Deployment

* **Streamlit UI**: Upload image â†’ model predicts â†’ urgency ranking + Gradâ€‘CAM heatmaps.
* **FastAPI endpoint**: `/predict` returns JSON with perâ€‘class probabilities, urgency score, latency.
* **ONNX/TFLite export**: Optional edge/mobile deployment with quantization.

---

## ğŸ“‘ Deliverables

* âœ… Dataset (â‰¥500 images, â‰¥40% curated/selfâ€‘collected)
* âœ… Baseline + 3 improvements
* âœ… Full evaluation & ablations
* âœ… Working demo (web app)
* âœ… Data Card (2 pages)
* âœ… Research Paper (PDF, template format)
* âœ… PPT deck (10â€“12 slides)
* âœ… Recorded videos (5 stages)

---

## ğŸ“… Timeline

* **Week 1**: Define problem, collect pilot data, baseline.
* **Week 2**: Expand dataset, train baseline to convergence, start deployment.
* **Week 3**: Add improvements (backbone, loss, calibration), error analysis, export model.
* **Week 4**: Final evaluation, deployment polish, documentation, videos, submission.

---

## ğŸ“œ License & Citation

* Openâ€‘source license (MIT or Apache 2.0 recommended).
* Cite all datasets (CheXpert, NIH, PadChest, etc.) and external libraries used.

---

## ğŸ™ Acknowledgements

* Public datasets: CheXpert, NIH ChestXâ€‘ray14, PadChest, Shenzhen & Montgomery TB datasets.
* Libraries: PyTorch, Torchvision, Timm, Albumentations, Gradâ€‘CAM, Streamlit, FastAPI.
